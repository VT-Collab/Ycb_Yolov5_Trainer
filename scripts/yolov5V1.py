#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""YOLOv5Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hZyY5dyyGh1THnhOzzB4vI18TVKprDZT
"""

# !pip3 install torch==1.11.0 torchvision==0.12.0 torchaudio===0.11.0 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111
# !git clone https://github.com/ultralytics/yolov5
# !cd yolov5 & pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt  # install

import torch
from matplotlib import pyplot as plt
import numpy as np
import cv2

model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')

model.conf = 0.65  # confidence threshold (0-1)
model.iou = 0.70  # NMS IoU threshold (0-1)
# model.classes = [0]  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs

# model = torch.hub.load('ultralytics/yolov5', 'yolov5I6', pretrained=True)
# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# model

# img = 'https://www.helpguide.org/wp-content/uploads/man-in-bed-cradling-cat.jpg'

# results = model(img)
# results.print()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 
# plt.imshow(np.squeeze(results.render()))
# plt.show()

# results.crop()
# ReturnedArray = results.display(pprint=True,labels=True,crop=True)
# for jsonObject in ReturnedArray:
#   strSplit = str.split(jsonObject['label'])
#   confidence = strSplit[1][2:]
#   classification = strSplit[0]
#   print('Detected Element Class: {} | Confidence Threshold: {}%'.format(str.capitalize(classification), confidence))
#   # print('Detected Element: {} | Confidence Threshold: {}'.format(jsonObject['label'], jsonObject['conf']))

cap = cv2.VideoCapture(-1)
while cap.isOpened():
    ret, frame = cap.read()
    
    # Make detections 
    results = model(frame)
    
    cv2.imshow('Live Detection', np.squeeze(results.render()))
    
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()